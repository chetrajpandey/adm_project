{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b61a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from models.predict import Custom_AlexNet\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.nn.functional import softmax\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", Warning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6c8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyJP2Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        hmi = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(hmi)\n",
    "            \n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        y_class = self.annotations.iloc[index, 2]\n",
    "        return (image, y_label, y_class, img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90919e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:1' if use_cuda else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a294e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "datapath = '/data/hmi_jpgs_512/'\n",
    "partition3_path_6 = 'labels_store/6_M_Partition3_.csv'\n",
    "partition4_path_6 = 'labels_store/6_M_Partition4_.csv'\n",
    "partition3_path_12 = 'labels_store/12_M_Partition3_.csv'\n",
    "partition4_path_12 = 'labels_store/12_M_Partition4_.csv'\n",
    "partition3_path_18 = 'labels_store/18_M_Partition3_.csv'\n",
    "partition4_path_18 = 'labels_store/18_M_Partition4_.csv'\n",
    "partition3_path_24 = 'labels_store/24_M_Partition3_.csv'\n",
    "partition4_path_24 = 'labels_store/24_M_Partition4_.csv'\n",
    "transformations = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "part3_6 = MyJP2Dataset(csv_file = partition3_path_6, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part4_6 = MyJP2Dataset(csv_file = partition4_path_6, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part3_12 = MyJP2Dataset(csv_file = partition3_path_12, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part4_12 = MyJP2Dataset(csv_file = partition4_path_12, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part3_18 = MyJP2Dataset(csv_file = partition3_path_18, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part4_18 = MyJP2Dataset(csv_file = partition4_path_18, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part3_24 = MyJP2Dataset(csv_file = partition3_path_24, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part4_24 = MyJP2Dataset(csv_file = partition4_path_24, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617bb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "part3_loader_6 = DataLoader(dataset=part3_6, batch_size=12, num_workers=4, shuffle=False)\n",
    "part4_loader_6 = DataLoader(dataset=part4_6, batch_size=12, num_workers=4, shuffle=False)\n",
    "part3_loader_12 = DataLoader(dataset=part3_12, batch_size=12, num_workers=4, shuffle=False)\n",
    "part4_loader_12 = DataLoader(dataset=part4_12, batch_size=12, num_workers=4, shuffle=False)\n",
    "part3_loader_18 = DataLoader(dataset=part3_18, batch_size=12, num_workers=4, shuffle=False)\n",
    "part4_loader_18 = DataLoader(dataset=part4_18, batch_size=12, num_workers=4, shuffle=False)\n",
    "part3_loader_24 = DataLoader(dataset=part3_24, batch_size=12, num_workers=4, shuffle=False)\n",
    "part4_loader_24 = DataLoader(dataset=part4_24, batch_size=12, num_workers=4, shuffle=False)\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6b13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PATH1 = 'trained_models/six.pth'\n",
    "model_PATH2 = 'trained_models/twelve.pth'\n",
    "model_PATH3 = 'trained_models/eighteen.pth'\n",
    "model_PATH4 = 'trained_models/twentyfour.pth'\n",
    "weights1 = torch.load(model_PATH1, map_location=device)\n",
    "weights2 = torch.load(model_PATH2, map_location=device)\n",
    "weights3 = torch.load(model_PATH3, map_location=device)\n",
    "weights4 = torch.load(model_PATH4, map_location=device)\n",
    "test_model = Custom_AlexNet().to(device)\n",
    "\n",
    "\n",
    "#Generalize this\n",
    "# checkpoint = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f314da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_Compatible_preds_and_targets(model_prediction_list, model_target_list, model_path_list, model_class_list):\n",
    "    y_pred_list = []\n",
    "    preds = []\n",
    "    target_list = []\n",
    "    tgts = []\n",
    "    path_list = []\n",
    "    path = []\n",
    "    class_list = []\n",
    "    clss = []\n",
    "    y_pred_list = [a.squeeze().tolist() for a in model_prediction_list]\n",
    "    preds = [item for sublist in y_pred_list for item in sublist]\n",
    "    target_list = [a.squeeze().tolist() for a in model_target_list]\n",
    "    tgts = [item for sublist in target_list for item in sublist]\n",
    "    path_list = [a for a in model_path_list]\n",
    "    path = [item for sublist in path_list for item in sublist]\n",
    "    class_list = [a for a in model_class_list]\n",
    "    clss = [item for sublist in class_list for item in sublist]\n",
    "    return preds,tgts, path, clss\n",
    "\n",
    "\n",
    "def accuracy_score(prediction, target):\n",
    "    TN, FP, FN, TP = confusion_matrix(target, prediction).ravel()\n",
    "    print(\"TP: \", TP, \"FP: \", FP, \"TN: \", TN, \"FN: \", FN)\n",
    "    #TSS Computation also known as \"recall\"\n",
    "    tp_rate = TP / float(TP + FN) if TP > 0 else 0  \n",
    "    fp_rate = FP / float(FP + TN) if FP > 0 else 0\n",
    "    TSS = tp_rate - fp_rate\n",
    "    \n",
    "    #HSS2 Computation\n",
    "    N = TN + FP\n",
    "    P = TP + FN\n",
    "    HSS = (2 * (TP * TN - FN * FP)) / float((P * (FN + TN) + (TP + FP) * N))\n",
    "\n",
    "    return TSS, HSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49102ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(checkpoint, test_loader, desc ):\n",
    "    test_target_list=[]\n",
    "    test_prediction_list=[]\n",
    "    test_path_list = []\n",
    "    test_class_list = []\n",
    "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_model.eval()\n",
    "    print('***********************', desc, '*************************')\n",
    "    with torch.no_grad():\n",
    "        for d, t, cls, path in test_loader:\n",
    "            # Get data to cuda if possible\n",
    "            d = d.to(device=device)\n",
    "            t = t.to(device=device)\n",
    "    #         pa = path.to(device=device)\n",
    "            test_target_list.append(t)\n",
    "            test_path_list.append(list(path))\n",
    "            test_class_list.append(list(cls))\n",
    "    #         print(list(path))\n",
    "            # forward pass\n",
    "            s = test_model(d)\n",
    "            #print(\"scores\", s)\n",
    "\n",
    "            # validation batch loss and accuracy\n",
    "    #         l = criterion(s, t)\n",
    "            p = softmax(s,dim=1)\n",
    "    #         print(p[:,1])\n",
    "            test_prediction_list.append(p[:,1])\n",
    "            # accumulating the val_loss and accuracy\n",
    "    #         val_loss += l.item()\n",
    "            #val_acc += acc.item()\n",
    "            del d,t,s,p\n",
    "    a, b, c, d = sklearn_Compatible_preds_and_targets(test_prediction_list, test_target_list, test_path_list, test_class_list)\n",
    "    preds = [int(i >=0.5) for i in a]\n",
    "    print(accuracy_score(preds, b))\n",
    "    prob_list = pd.DataFrame(\n",
    "    {'timestamp': c,\n",
    "     'flare_prob': a,\n",
    "     'target': b,\n",
    "     'goes_class': d\n",
    "    })\n",
    "\n",
    "    print(prob_list['target'].value_counts())\n",
    "    prob_list['timestamp'] = prob_list['timestamp'].apply(lambda row: row[35:-4])\n",
    "    prob_list['timestamp'] = pd.to_datetime(prob_list['timestamp'], format='%Y.%m.%d_%H.%M.%S')\n",
    "    return prob_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d16bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** 6 hours Partition-3 *************************\n",
      "TP:  578 FP:  3724 TN:  12020 FN:  350\n",
      "(0.38631027474067836, 0.1425112127188712)\n",
      "0    15744\n",
      "1      928\n",
      "Name: target, dtype: int64\n",
      "*********************** 6 hours Partition-4 *************************\n",
      "TP:  832 FP:  4760 TN:  10955 FN:  175\n",
      "(0.5233211616678795, 0.16715871303559052)\n",
      "0    15715\n",
      "1     1007\n",
      "Name: target, dtype: int64\n",
      "*********************** 12 hours Partition-3 *************************\n",
      "TP:  1023 FP:  4021 TN:  11131 FN:  497\n",
      "(0.4076488078697271, 0.19954200819950868)\n",
      "0    15152\n",
      "1     1520\n",
      "Name: target, dtype: int64\n",
      "*********************** 12 hours Partition-4 *************************\n",
      "TP:  1475 FP:  5004 TN:  9996 FN:  247\n",
      "(0.5229621370499419, 0.23528490862397564)\n",
      "0    15000\n",
      "1     1722\n",
      "Name: target, dtype: int64\n",
      "*********************** 18 hours Partition-3 *************************\n",
      "TP:  814 FP:  1652 TN:  13031 FN:  1175\n",
      "(0.2967398126185199, 0.2688673488085104)\n",
      "0    14683\n",
      "1     1989\n",
      "Name: target, dtype: int64\n",
      "*********************** 18 hours Partition-4 *************************\n",
      "TP:  1340 FP:  2293 TN:  12176 FN:  913\n",
      "(0.4362857954547023, 0.34665194587938974)\n",
      "0    14469\n",
      "1     2253\n",
      "Name: target, dtype: int64\n",
      "*********************** 24 hours Partition-3 *************************\n",
      "TP:  1542 FP:  2762 TN:  11544 FN:  824\n",
      "(0.4586670360041404, 0.3418250302259975)\n",
      "0    14306\n",
      "1     2366\n",
      "Name: target, dtype: int64\n",
      "*********************** 24 hours Partition-4 *************************\n",
      "TP:  2231 FP:  4080 TN:  9951 FN:  460\n",
      "(0.5382751380185633, 0.3487113466933936)\n",
      "0    14031\n",
      "1     2691\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "res3_6 = predict(weights1, part3_loader_6, '6 hours Partition-3')\n",
    "res4_6 = predict(weights1, part4_loader_6, '6 hours Partition-4')\n",
    "res3_12 = predict(weights2, part3_loader_12, '12 hours Partition-3')\n",
    "res4_12 = predict(weights2, part4_loader_12, '12 hours Partition-4')\n",
    "res3_18 = predict(weights3, part3_loader_18, '18 hours Partition-3')\n",
    "res4_18 = predict(weights3, part4_loader_18, '18 hours Partition-4')\n",
    "res3_24 = predict(weights4, part3_loader_24, '24 hours Partition-3')\n",
    "res4_24 = predict(weights4, part4_loader_24, '24 hours Partition-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8531c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3_6.to_csv(r'results/res3_6.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res4_6.to_csv(r'results/res4_6.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res3_12.to_csv(r'results/res3_12.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res4_12.to_csv(r'results/res4_12.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res3_18.to_csv(r'results/res3_18.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res4_18.to_csv(r'results/res4_18.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res3_24.to_csv(r'results/res3_24.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])\n",
    "res4_24.to_csv(r'results/res4_24.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target', 'goes_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591bb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging(df):\n",
    "    lis=[]\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=24))))]\n",
    "        avg = sel['flare_prob'].mean()\n",
    "        lis.append([str(df.timestamp[i]), avg, df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "    \n",
    "\n",
    "def max_voting(df):\n",
    "    lis=[]\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=24))))]\n",
    "        t = threshold(sel['flare_prob'])\n",
    "        vals,counts = np.unique(t, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        lis.append([str(df.timestamp[i]), vals[index], df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "    \n",
    "\n",
    "def weighted(df):\n",
    "    lis=[]\n",
    "#     weights = np.array([0.025, 0.025, 0.05, 0.05, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.15])\n",
    "    weights = np.array([0.025, 0.026, 0.027, 0.0285, 0.0295, 0.0305])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=24))))]\n",
    "        if sel['flare_prob'].values.size<6:\n",
    "            prob = sel['flare_prob'].mean()\n",
    "        else:\n",
    "            temp = np.multiply(sel['flare_prob'].values, weights)\n",
    "            prob = np.mean(temp)\n",
    "        lis.append([str(df.timestamp[i]), prob, df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "\n",
    "def threshold(df):\n",
    "    y_pred = df.to_numpy().reshape(len(df),)\n",
    "    yp = np.where(y_pred >= 0.5, 1, 0)\n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca1cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequential(fold, func, desc):\n",
    "    pred = func(fold)\n",
    "    zero_ones = threshold(pred['prob'])\n",
    "    TSS, HSS = accuracy_score(zero_ones, pred['tar'].to_numpy().reshape(len(pred['tar']),))\n",
    "    print('************************', desc, '***************************')\n",
    "    print('TSS: {:.4f} | HSS: {:.4f}'.format(TSS, HSS))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9309b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  587 FP:  3653 TN:  12091 FN:  341\n",
      "************************ Averaging on Partition-3  - 6 hours pred window ***************************\n",
      "TSS: 0.4005 | HSS: 0.1495\n",
      "\n",
      "\n",
      "\n",
      "TP:  824 FP:  4864 TN:  10851 FN:  183\n",
      "************************ Averaging on Partition-4  - 6 hours pred window ***************************\n",
      "TSS: 0.5088 | HSS: 0.1602\n",
      "\n",
      "\n",
      "\n",
      "TP:  1072 FP:  3951 TN:  11201 FN:  448\n",
      "************************ Averaging on Partition-3  - 12 hours pred window ***************************\n",
      "TSS: 0.4445 | HSS: 0.2182\n",
      "\n",
      "\n",
      "\n",
      "TP:  1506 FP:  5138 TN:  9862 FN:  216\n",
      "************************ Averaging on Partition-4  - 12 hours pred window ***************************\n",
      "TSS: 0.5320 | HSS: 0.2349\n",
      "\n",
      "\n",
      "\n",
      "TP:  821 FP:  1503 TN:  13180 FN:  1168\n",
      "************************ Averaging on Partition-3  - 18 hours pred window ***************************\n",
      "TSS: 0.3104 | HSS: 0.2893\n",
      "\n",
      "\n",
      "\n",
      "TP:  1301 FP:  2332 TN:  12137 FN:  952\n",
      "************************ Averaging on Partition-4  - 18 hours pred window ***************************\n",
      "TSS: 0.4163 | HSS: 0.3308\n",
      "\n",
      "\n",
      "\n",
      "TP:  1574 FP:  2627 TN:  11679 FN:  792\n",
      "************************ Averaging on Partition-3  - 24 hours pred window ***************************\n",
      "TSS: 0.4816 | HSS: 0.3639\n",
      "\n",
      "\n",
      "\n",
      "TP:  2174 FP:  4172 TN:  9859 FN:  517\n",
      "************************ Averaging on Partition-4  - 24 hours pred window ***************************\n",
      "TSS: 0.5105 | HSS: 0.3296\n",
      "\n",
      "\n",
      "\n",
      "TP:  587 FP:  3653 TN:  12091 FN:  341\n",
      "************************ Majority Voting On Partition-3  - 6 hours pred window ***************************\n",
      "TSS: 0.4005 | HSS: 0.1495\n",
      "\n",
      "\n",
      "\n",
      "TP:  824 FP:  4864 TN:  10851 FN:  183\n",
      "************************ Majority Voting On Partition-4  - 6 hours pred window ***************************\n",
      "TSS: 0.5088 | HSS: 0.1602\n",
      "\n",
      "\n",
      "\n",
      "TP:  1072 FP:  3951 TN:  11201 FN:  448\n",
      "************************ Majority Voting On Partition-3  - 12 hours pred window ***************************\n",
      "TSS: 0.4445 | HSS: 0.2182\n",
      "\n",
      "\n",
      "\n",
      "TP:  1506 FP:  5138 TN:  9862 FN:  216\n",
      "************************ Majority Voting On Partition-4  - 12 hours pred window ***************************\n",
      "TSS: 0.5320 | HSS: 0.2349\n",
      "\n",
      "\n",
      "\n",
      "TP:  821 FP:  1503 TN:  13180 FN:  1168\n",
      "************************ Majority Voting On Partition-3  - 18 hours pred window ***************************\n",
      "TSS: 0.3104 | HSS: 0.2893\n",
      "\n",
      "\n",
      "\n",
      "TP:  1301 FP:  2332 TN:  12137 FN:  952\n",
      "************************ Majority Voting On Partition-4  - 18 hours pred window ***************************\n",
      "TSS: 0.4163 | HSS: 0.3308\n",
      "\n",
      "\n",
      "\n",
      "TP:  1574 FP:  2627 TN:  11679 FN:  792\n",
      "************************ Majority Voting On Partition-3  - 24 hours pred window ***************************\n",
      "TSS: 0.4816 | HSS: 0.3639\n",
      "\n",
      "\n",
      "\n",
      "TP:  2174 FP:  4172 TN:  9859 FN:  517\n",
      "************************ Majority Voting On Partition-4  - 24 hours pred window ***************************\n",
      "TSS: 0.5105 | HSS: 0.3296\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Averaging\n",
    "compare_sequential(res3_6, averaging, 'Averaging on Partition-3  - 6 hours pred window')\n",
    "compare_sequential(res4_6, averaging, 'Averaging on Partition-4  - 6 hours pred window')\n",
    "compare_sequential(res3_12, averaging, 'Averaging on Partition-3  - 12 hours pred window')\n",
    "compare_sequential(res4_12, averaging, 'Averaging on Partition-4  - 12 hours pred window')\n",
    "compare_sequential(res3_18, averaging, 'Averaging on Partition-3  - 18 hours pred window')\n",
    "compare_sequential(res4_18, averaging, 'Averaging on Partition-4  - 18 hours pred window')\n",
    "compare_sequential(res3_24, averaging, 'Averaging on Partition-3  - 24 hours pred window')\n",
    "compare_sequential(res4_24, averaging, 'Averaging on Partition-4  - 24 hours pred window')\n",
    "\n",
    "#Max Voting\n",
    "compare_sequential(res3_6, averaging, 'Majority Voting On Partition-3  - 6 hours pred window')\n",
    "compare_sequential(res4_6, averaging, 'Majority Voting On Partition-4  - 6 hours pred window')\n",
    "compare_sequential(res3_12, averaging, 'Majority Voting On Partition-3  - 12 hours pred window')\n",
    "compare_sequential(res4_12, averaging, 'Majority Voting On Partition-4  - 12 hours pred window')\n",
    "compare_sequential(res3_18, averaging, 'Majority Voting On Partition-3  - 18 hours pred window')\n",
    "compare_sequential(res4_18, averaging, 'Majority Voting On Partition-4  - 18 hours pred window')\n",
    "compare_sequential(res3_24, averaging, 'Majority Voting On Partition-3  - 24 hours pred window')\n",
    "compare_sequential(res4_24, averaging, 'Majority Voting On Partition-4  - 24 hours pred window')\n",
    "# #Weighted\n",
    "# compare_sequential(fold1, weighted, 'weighted Fold-1')\n",
    "# compare_sequential(fold2, weighted, 'weighted Fold-2')\n",
    "# compare_sequential(fold3, weighted, 'weighted Fold-3')\n",
    "# compare_sequential(fold4, weighted, 'weighted Fold-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed460b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

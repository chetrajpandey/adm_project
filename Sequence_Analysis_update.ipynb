{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b61a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from models.predict import Custom_AlexNet\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.nn.functional import softmax\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", Warning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6c8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyJP2Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        hmi = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(hmi)\n",
    "            \n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        \n",
    "        return (image, y_label, img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90919e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a294e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "datapath = '/data/hmi_jpgs_512/'\n",
    "partition1_path = '/data/hmi_jpgs/vids_data_labels/Fold1_val.csv'\n",
    "partition2_path = '/data/hmi_jpgs/vids_data_labels/Fold2_val.csv'\n",
    "partition3_path = '/data/hmi_jpgs/vids_data_labels/Fold3_val.csv'\n",
    "partition4_path = '/data/hmi_jpgs/vids_data_labels/Fold4_val.csv'\n",
    "\n",
    "\n",
    "transformations = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "part1 = MyJP2Dataset(csv_file = partition1_path, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part2 = MyJP2Dataset(csv_file = partition2_path, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part3 = MyJP2Dataset(csv_file = partition3_path, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)\n",
    "part4 = MyJP2Dataset(csv_file = partition4_path, \n",
    "                             root_dir = datapath,\n",
    "                             transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617bb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_loader = DataLoader(dataset=part1, batch_size=24, num_workers=4, shuffle=False)\n",
    "part2_loader = DataLoader(dataset=part2, batch_size=24, num_workers=4, shuffle=False)\n",
    "part3_loader = DataLoader(dataset=part3, batch_size=24, num_workers=4, shuffle=False)\n",
    "part4_loader = DataLoader(dataset=part4, batch_size=24, num_workers=4, shuffle=False)\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6b13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_PATH1 = 'trained_models/new-fold1.pth'\n",
    "model_PATH2 = 'trained_models/new-fold2.pth'\n",
    "model_PATH3 = 'trained_models/new-fold3.pth'\n",
    "model_PATH4 = 'trained_models/new-fold4.pth'\n",
    "weights1 = torch.load(model_PATH1, map_location=torch.device(\"cpu\"))\n",
    "weights2 = torch.load(model_PATH2, map_location=torch.device(\"cpu\"))\n",
    "weights3 = torch.load(model_PATH3, map_location=torch.device(\"cpu\"))\n",
    "weights4 = torch.load(model_PATH4, map_location=torch.device(\"cpu\"))\n",
    "test_model = Custom_AlexNet().to(device)\n",
    "\n",
    "\n",
    "#Generalize this\n",
    "# checkpoint = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f314da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_Compatible_preds_and_targets(model_prediction_list, model_target_list, model_path_list):\n",
    "    y_pred_list = []\n",
    "    preds = []\n",
    "    target_list = []\n",
    "    tgts = []\n",
    "    path_list = []\n",
    "    path = []\n",
    "    y_pred_list = [a.squeeze().tolist() for a in model_prediction_list]\n",
    "    preds = [item for sublist in y_pred_list for item in sublist]\n",
    "    target_list = [a.squeeze().tolist() for a in model_target_list]\n",
    "    tgts = [item for sublist in target_list for item in sublist]\n",
    "    path_list = [a for a in model_path_list]\n",
    "    path = [item for sublist in path_list for item in sublist]\n",
    "    return preds,tgts, path\n",
    "\n",
    "\n",
    "def accuracy_score(prediction, target):\n",
    "    TN, FP, FN, TP = confusion_matrix(target, prediction).ravel()\n",
    "    print(\"TP: \", TP, \"FP: \", FP, \"TN: \", TN, \"FN: \", FN)\n",
    "    #TSS Computation also known as \"recall\"\n",
    "    tp_rate = TP / float(TP + FN) if TP > 0 else 0  \n",
    "    fp_rate = FP / float(FP + TN) if FP > 0 else 0\n",
    "    TSS = tp_rate - fp_rate\n",
    "    \n",
    "    #HSS2 Computation\n",
    "    N = TN + FP\n",
    "    P = TP + FN\n",
    "    HSS = (2 * (TP * TN - FN * FP)) / float((P * (FN + TN) + (TP + FP) * N))\n",
    "\n",
    "    return TSS, HSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49102ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(checkpoint, test_loader, desc ):\n",
    "    test_target_list=[]\n",
    "    test_prediction_list=[]\n",
    "    test_path_list = []\n",
    "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_model.eval()\n",
    "    print('***********************', desc, '*************************')\n",
    "    with torch.no_grad():\n",
    "        for d, t, path in test_loader:\n",
    "            # Get data to cuda if possible\n",
    "            d = d.to(device=device)\n",
    "            t = t.to(device=device)\n",
    "    #         pa = path.to(device=device)\n",
    "            test_target_list.append(t)\n",
    "            test_path_list.append(list(path))\n",
    "    #         print(list(path))\n",
    "            # forward pass\n",
    "            s = test_model(d)\n",
    "            #print(\"scores\", s)\n",
    "\n",
    "            # validation batch loss and accuracy\n",
    "    #         l = criterion(s, t)\n",
    "            p = softmax(s,dim=1)\n",
    "    #         print(p[:,1])\n",
    "            test_prediction_list.append(p[:,1])\n",
    "            # accumulating the val_loss and accuracy\n",
    "    #         val_loss += l.item()\n",
    "            #val_acc += acc.item()\n",
    "            del d,t,s,p\n",
    "    a, b, c = sklearn_Compatible_preds_and_targets(test_prediction_list, test_target_list, test_path_list)\n",
    "    preds = [int(i >=0.5) for i in a]\n",
    "    print(accuracy_score(preds, b))\n",
    "    prob_list = pd.DataFrame(\n",
    "    {'timestamp': c,\n",
    "     'flare_prob': a,\n",
    "     'target': b\n",
    "    })\n",
    "\n",
    "    print(prob_list['target'].value_counts())\n",
    "    prob_list['timestamp'] = prob_list['timestamp'].apply(lambda row: row[35:-4])\n",
    "    prob_list['timestamp'] = pd.to_datetime(prob_list['timestamp'], format='%Y.%m.%d_%H.%M.%S')\n",
    "    return prob_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d16bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** Fold-1 Results *************************\n",
      "TP:  1720 FP:  1943 TN:  10511 FN:  614\n",
      "(0.5809181730499171, 0.47177415659692445)\n",
      "0    12454\n",
      "1     2334\n",
      "Name: target, dtype: int64\n",
      "*********************** Fold-2 Results *************************\n",
      "TP:  1155 FP:  3083 TN:  10772 FN:  457\n",
      "(0.49398229446599073, 0.28724094275141926)\n",
      "0    13855\n",
      "1     1612\n",
      "Name: target, dtype: int64\n",
      "*********************** Fold-3 Results *************************\n",
      "TP:  1585 FP:  2668 TN:  11640 FN:  779\n",
      "(0.4840046650744297, 0.3629519598840223)\n",
      "0    14308\n",
      "1     2364\n",
      "Name: target, dtype: int64\n",
      "*********************** Fold-4 Results *************************\n",
      "TP:  1706 FP:  2241 TN:  11791 FN:  984\n",
      "(0.47449435808963475, 0.39911957177843904)\n",
      "0    14032\n",
      "1     2690\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fold1 = predict(weights1, part1_loader, 'Fold-1 Results')\n",
    "fold2 = predict(weights2, part2_loader, 'Fold-2 Results')\n",
    "fold3 = predict(weights3, part3_loader, 'Fold-3 Results')\n",
    "fold4 = predict(weights4, part4_loader, 'Fold-4 Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8531c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1.to_csv(r'fold1_res.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target'])\n",
    "fold2.to_csv(r'fold2_res.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target'])\n",
    "fold3.to_csv(r'fold3_res.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target'])\n",
    "fold4.to_csv(r'fold4_res.csv', index=False, header=True, columns=['timestamp', 'flare_prob', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "462dfa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flare_prob</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>0.028676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>0.032177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>0.036595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>0.038249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14783</th>\n",
       "      <td>2018-03-31 19:00:00</td>\n",
       "      <td>0.020684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14784</th>\n",
       "      <td>2018-03-31 20:00:00</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14785</th>\n",
       "      <td>2018-03-31 21:00:00</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14786</th>\n",
       "      <td>2018-03-31 22:00:00</td>\n",
       "      <td>0.020855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14787</th>\n",
       "      <td>2018-03-31 23:00:00</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14788 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  flare_prob  target\n",
       "0     2011-01-01 00:00:00    0.026611       0\n",
       "1     2011-01-01 01:00:00    0.028676       0\n",
       "2     2011-01-01 02:00:00    0.032177       0\n",
       "3     2011-01-01 03:00:00    0.036595       0\n",
       "4     2011-01-01 04:00:00    0.038249       0\n",
       "...                   ...         ...     ...\n",
       "14783 2018-03-31 19:00:00    0.020684       0\n",
       "14784 2018-03-31 20:00:00    0.020400       0\n",
       "14785 2018-03-31 21:00:00    0.021527       0\n",
       "14786 2018-03-31 22:00:00    0.020855       0\n",
       "14787 2018-03-31 23:00:00    0.020599       0\n",
       "\n",
       "[14788 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "591bb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging(df):\n",
    "    lis=[]\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=12))))]\n",
    "        avg = sel['flare_prob'].mean()\n",
    "        lis.append([str(df.timestamp[i]), avg, df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "    \n",
    "\n",
    "def max_voting(df):\n",
    "    lis=[]\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=11))))]\n",
    "        t = threshold(sel['flare_prob'])\n",
    "        vals,counts = np.unique(t, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        lis.append([str(df.timestamp[i]), vals[index], df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "    \n",
    "\n",
    "def weighted(df):\n",
    "    lis=[]\n",
    "#     weights = np.array([0.025, 0.025, 0.05, 0.05, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.15])\n",
    "    weights = np.array([0.025, 0.026, 0.027, 0.0285, 0.0295, 0.0305])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sel = df[((df.timestamp<=df.timestamp[i]) & (df.timestamp>(df.timestamp[i]-timedelta(hours=6))))]\n",
    "        if sel['flare_prob'].values.size<6:\n",
    "            prob = sel['flare_prob'].mean()\n",
    "        else:\n",
    "            temp = np.multiply(sel['flare_prob'].values, weights)\n",
    "            prob = np.mean(temp)\n",
    "        lis.append([str(df.timestamp[i]), prob, df.target[i]])\n",
    "    df_result = pd.DataFrame(lis, columns=['time', 'prob', 'tar'])\n",
    "    return df_result\n",
    "\n",
    "def threshold(df):\n",
    "    y_pred = df.to_numpy().reshape(len(df),)\n",
    "    yp = np.where(y_pred >= 0.5, 1, 0)\n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ca1cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequential(fold, func, desc):\n",
    "    pred = func(fold)\n",
    "    zero_ones = threshold(pred['prob'])\n",
    "    TSS, HSS = accuracy_score(zero_ones, pred['tar'].to_numpy().reshape(len(pred['tar']),))\n",
    "    print('************************', desc, '***************************')\n",
    "    print('TSS: {:.4f} | HSS: {:.4f}'.format(TSS, HSS))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9309b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1716 FP:  1895 TN:  10559 FN:  618\n",
      "************************ max_voting Fold-1 ***************************\n",
      "TSS: 0.5831 | HSS: 0.4770\n",
      "\n",
      "\n",
      "\n",
      "TP:  1154 FP:  3052 TN:  10803 FN:  458\n",
      "************************ max_voting Fold-2 ***************************\n",
      "TSS: 0.4956 | HSS: 0.2897\n",
      "\n",
      "\n",
      "\n",
      "TP:  1613 FP:  2602 TN:  11706 FN:  751\n",
      "************************ max_voting Fold-3 ***************************\n",
      "TSS: 0.5005 | HSS: 0.3772\n",
      "\n",
      "\n",
      "\n",
      "TP:  1714 FP:  2191 TN:  11841 FN:  976\n",
      "************************ max_voting Fold-4 ***************************\n",
      "TSS: 0.4810 | HSS: 0.4068\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Averaging\n",
    "# compare_sequential(fold1, averaging, 'Averaging Fold-1')\n",
    "# compare_sequential(fold2, averaging, 'Averaging Fold-2')\n",
    "# compare_sequential(fold3, averaging, 'Averaging Fold-3')\n",
    "# compare_sequential(fold4, averaging, 'Averaging Fold-4')\n",
    "\n",
    "#Max Voting\n",
    "compare_sequential(fold1, max_voting, 'max_voting Fold-1')\n",
    "compare_sequential(fold2, max_voting, 'max_voting Fold-2')\n",
    "compare_sequential(fold3, max_voting, 'max_voting Fold-3')\n",
    "compare_sequential(fold4, max_voting, 'max_voting Fold-4')\n",
    "\n",
    "# #Weighted\n",
    "# compare_sequential(fold1, weighted, 'weighted Fold-1')\n",
    "# compare_sequential(fold2, weighted, 'weighted Fold-2')\n",
    "# compare_sequential(fold3, weighted, 'weighted Fold-3')\n",
    "# compare_sequential(fold4, weighted, 'weighted Fold-4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
